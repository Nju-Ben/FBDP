1、将traindata中positive,neutral,negative三个文件夹下的txt分别合并，并且只保留新闻内容，形成positive.txt,neutral.txt,negative.txt三个文本文档。合并前的txt内容是新的文件中的一行。如positive.txt文件中

输入:Trainingdata数据集
输出:positive.txt,neutral.txt,negative.txt
处理代码:trainingdataprocess.py

2、将第一步得到的三个分类下的文档进行分词，统计词频(词频用于计算特征值)。

输入:positive.txt,neutral.txt,negative.txt
输出:positive1.txt,neutral.txt,negative1.txt
处理代码:wordcount2.java及其项目

3.卡方检验挑选特征词，卡方=(AD-BC)^2/((A+B)*(C+D))，其中A为积极文件夹中包含该词的txt数目，B为其他两个文件夹中包含该词的txt数目，C为积极文件夹中不包含该词的txt数目，D为其他两个文件夹中不包含该词的txt数目，计算出卡方后，按卡方大小进行排序，每个分类凑够1000词，然后去重，剩下约670词。

输入:
positive.txt positive1.txt
negative.txt negative1.txt
neutral.txt neutral1.txt

输出:newfeatureword.txt
处理代码:chisquaretest.py

4.计算词频:每一类特征上的值为该分类下特征词处于总词数
输入:positive1.txt,neutral.txt,negative1.txt
输出:newfeature.txt
处理代码:featureprocess.txt

5.测试集预处理
将公司的所有新闻标题进行合并。
输入:fulldata.txt
输出:testdata.txt
处理代码fulldataprocess.py

6.测试集进行分类
原理:将三类特征的特征向量数据存储在全局变量中，读取testdata.txt数据,并行处理时，对于每一个公司的新闻标题，扫描特征词，若特征词出现在标题中，则按三类，乘以其特征值，否则乘以某一调整后数值，这样能计算出三类特征的P(Yi|X),再乘以P（Yi），比较i=1,2,3,时P(Yi|X)*P（Yi）大小，最大的那个即为分类。
输入:
testdata.txt(hdfs)
feature.txt(本地)
输出
result.txt
处理代码 wordcount4.java及其项目





















